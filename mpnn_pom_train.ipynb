{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Example script for training MPNN-POM model"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "id": "b62ce304-4377-4459-91be-98c2fc440262"
            },
            "outputs": [],
            "source": "import deepchem as dc\nfrom openpom.feat.graph_featurizer import GraphFeaturizer, GraphConvConstants\nfrom openpom.utils.data_utils import get_class_imbalance_ratio\nfrom openpom.models.mpnn_pom import MPNNPOMModel\nfrom datetime import datetime"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "id": "56293f1d-610f-4a42-80b8-10862aa33449"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "No of tasks:  138\n"
                }
            ],
            "source": "TASKS = [\n'alcoholic', 'aldehydic', 'alliaceous', 'almond', 'amber', 'animal',\n'anisic', 'apple', 'apricot', 'aromatic', 'balsamic', 'banana', 'beefy',\n'bergamot', 'berry', 'bitter', 'black currant', 'brandy', 'burnt',\n'buttery', 'cabbage', 'camphoreous', 'caramellic', 'cedar', 'celery',\n'chamomile', 'cheesy', 'cherry', 'chocolate', 'cinnamon', 'citrus', 'clean',\n'clove', 'cocoa', 'coconut', 'coffee', 'cognac', 'cooked', 'cooling',\n'cortex', 'coumarinic', 'creamy', 'cucumber', 'dairy', 'dry', 'earthy',\n'ethereal', 'fatty', 'fermented', 'fishy', 'floral', 'fresh', 'fruit skin',\n'fruity', 'garlic', 'gassy', 'geranium', 'grape', 'grapefruit', 'grassy',\n'green', 'hawthorn', 'hay', 'hazelnut', 'herbal', 'honey', 'hyacinth',\n'jasmin', 'juicy', 'ketonic', 'lactonic', 'lavender', 'leafy', 'leathery',\n'lemon', 'lily', 'malty', 'meaty', 'medicinal', 'melon', 'metallic',\n'milky', 'mint', 'muguet', 'mushroom', 'musk', 'musty', 'natural', 'nutty',\n'odorless', 'oily', 'onion', 'orange', 'orangeflower', 'orris', 'ozone',\n'peach', 'pear', 'phenolic', 'pine', 'pineapple', 'plum', 'popcorn',\n'potato', 'powdery', 'pungent', 'radish', 'raspberry', 'ripe', 'roasted',\n'rose', 'rummy', 'sandalwood', 'savory', 'sharp', 'smoky', 'soapy',\n'solvent', 'sour', 'spicy', 'strawberry', 'sulfurous', 'sweaty', 'sweet',\n'tea', 'terpenic', 'tobacco', 'tomato', 'tropical', 'vanilla', 'vegetable',\n'vetiver', 'violet', 'warm', 'waxy', 'weedy', 'winey', 'woody'\n]\nprint(\"No of tasks: \", len(TASKS))"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "id": "32762ced-1f05-4e31-bd0b-c4791b2bbbb9"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2023-08-21 07:50:22--  https://raw.githubusercontent.com/ARY2260/openpom/main/openpom/data/curated_datasets/curated_GS_LF_merged_4983.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1647971 (1.6M) [text/plain]\nSaving to: \u2018curated_GS_LF_merged_4983.csv\u2019\n\ncurated_GS_LF_merge 100%[===================>]   1.57M  3.94MB/s    in 0.4s    \n\n2023-08-21 07:50:23 (3.94 MB/s) - \u2018curated_GS_LF_merged_4983.csv\u2019 saved [1647971/1647971]\n\n"
                }
            ],
            "source": "# download curated dataset\n!wget https://raw.githubusercontent.com/ARY2260/openpom/main/openpom/data/curated_datasets/curated_GS_LF_merged_4983.csv\n\n# The curated dataset can also found at `openpom/data/curated_datasets/curated_GS_LF_merged_4983.csv` in the repo.\n\ninput_file = 'curated_GS_LF_merged_4983.csv' # or new downloaded file path"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "id": "02a8e768-cf1f-4ac4-9bfa-f880c331dfb5"
            },
            "outputs": [],
            "source": "# get dataset\n\nfeaturizer = GraphFeaturizer()\nsmiles_field = 'nonStereoSMILES'\nloader = dc.data.CSVLoader(tasks=TASKS,\n                   feature_field=smiles_field,\n                   featurizer=featurizer)\ndataset = loader.create_dataset(inputs=[input_file])\nn_tasks = len(dataset.tasks)"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "id": "16418292-9a25-4a3e-9211-586f4b36e0ea"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "4983"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "len(dataset)"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {
                "id": "62283fb9-574c-44b4-9bad-a3167ac759cd"
            },
            "outputs": [],
            "source": "# get train valid test splits\n\nrandomstratifiedsplitter = dc.splits.RandomStratifiedSplitter()\ntrain_dataset, test_dataset, valid_dataset = randomstratifiedsplitter.train_valid_test_split(dataset, frac_train = 0.8, frac_valid = 0.1, frac_test = 0.1, seed = 1)"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {
                "id": "e2866709-df9e-449f-ad89-f6c82daf398c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "train_dataset:  3999\nvalid_dataset:  498\ntest_dataset:  486\n"
                }
            ],
            "source": "print(\"train_dataset: \", len(train_dataset))\nprint(\"valid_dataset: \", len(valid_dataset))\nprint(\"test_dataset: \", len(test_dataset))\n"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {
                "id": "9be0c55e-0486-4209-b8dc-92359923ad2f"
            },
            "outputs": [],
            "source": "train_ratios = get_class_imbalance_ratio(train_dataset)\nassert len(train_ratios) == n_tasks"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {
                "id": "e6ea529c-63c4-4dd0-b5cc-59038660a38f"
            },
            "outputs": [],
            "source": "# learning_rate = ExponentialDecay(initial_rate=0.001, decay_rate=0.5, decay_steps=32*15, staircase=True)\nlearning_rate = 0.001"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {
                "id": "0a25af95-ff56-4821-ac96-a96e8a7f83fa"
            },
            "outputs": [],
            "source": "# initialize model\n\nmodel = MPNNPOMModel(n_tasks = n_tasks,\n                            batch_size=128,\n                            learning_rate=learning_rate,\n                            class_imbalance_ratio = train_ratios,\n                            loss_aggr_type = 'sum',\n                            node_out_feats = 100,\n                            edge_hidden_feats = 75,\n                            edge_out_feats = 100,\n                            num_step_message_passing = 5,\n                            mpnn_residual = True,\n                            message_aggregator_type = 'sum',\n                            mode = 'classification',\n                            number_atom_features = GraphConvConstants.ATOM_FDIM,\n                            number_bond_features = GraphConvConstants.BOND_FDIM,\n                            n_classes = 1,\n                            readout_type = 'set2set',\n                            num_step_set2set = 3,\n                            num_layer_set2set = 2,\n                            ffn_hidden_list= [392, 392],\n                            ffn_embeddings = 256,\n                            ffn_activation = 'relu',\n                            ffn_dropout_p = 0.12,\n                            ffn_dropout_at_input_no_act = False,\n                            weight_decay = 1e-5,\n                            self_loop = False,\n                            optimizer_name = 'adam',\n                            log_frequency = 32,\n                            model_dir = './examples/experiments',\n                            device_name='cuda')"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {
                "id": "3f73287c-f666-4fd9-8836-e8efef110db4"
            },
            "outputs": [],
            "source": "nb_epoch = 3"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {
                "id": "d1bd3782-a9ad-464e-94aa-6c4d6861f73d"
            },
            "outputs": [],
            "source": "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {
                "id": "8d56636a-63cb-4097-a01b-faaf07c15835"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "epoch 1/3 ; loss = 3.9557206630706787; train_scores = 0.6163758443655751; valid_scores = 0.615455680068517\nepoch 2/3 ; loss = 3.206171989440918; train_scores = 0.6657432066579966; valid_scores = 0.6640639214801205\nepoch 3/3 ; loss = 3.0010340213775635; train_scores = 0.782657725455088; valid_scores = 0.7870079992430258\n"
                }
            ],
            "source": "start_time = datetime.now()\nfor epoch in range(1, nb_epoch+1):\n        loss = model.fit(\n              train_dataset,\n              nb_epoch=1,\n              max_checkpoints_to_keep=1,\n              deterministic=False,\n              restore=epoch>1)\n        train_scores = model.evaluate(train_dataset, [metric])['roc_auc_score']\n        valid_scores = model.evaluate(valid_dataset, [metric])['roc_auc_score']\n        print(f\"epoch {epoch}/{nb_epoch} ; loss = {loss}; train_scores = {train_scores}; valid_scores = {valid_scores}\")\nmodel.save_checkpoint()\nend_time = datetime.now()"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {
                "id": "fe65d905-8cb5-4d6a-a9a8-6462e804f1f1"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "time_taken:  0:00:15.349649\ntest_score:  0.7731850240131496\n"
                }
            ],
            "source": "test_scores = model.evaluate(test_dataset, [metric])['roc_auc_score']\nprint(\"time_taken: \", str(end_time-start_time))\nprint(\"test_score: \", test_scores)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.11",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}